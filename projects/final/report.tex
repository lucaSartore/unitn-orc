\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{geometry}
\usepackage{float}
\usepackage[table,xcdraw]{xcolor}
\geometry{margin=1in}

\title{Optimization and Learning for Robot Control: Final Project}
\author{Luca Sartore - 256154}
\date{}


\begin{document}
\maketitle

\tableofcontents

\newpage

\section{Introduction}


This works aims to develop a neural network that approximate the output of an optimal control problem.

The system selected is pretty straightforward, a robot moves on a 1D space. At each iteration the robot
get a cost that is proportional to the squared control input, and to a positional cost.
The objective of the robot is to plan a trajectory with the least possible cost.

The tests where made with two systems, one named ``Simple'' where the robot's velocity is imply proportional
to the control's input, and one named ``Inertia'' where the robot has an inertia, and the 
control input thus become acceleration.

The system is trained using a Critic-Actor paradigm, and the result is evaluated in two main ways:
\begin{itemize}
    \item \textbf{Trajectory:} Here the optimal trajectories are compared with the trajectories obtained by the neural network
    \item \textbf{Computation time} In this test we compare the computational cost of the various approaches used to solve the same problem
\end{itemize}


\section{Creating a dataset using Optimal Control}


\subsection{Solving the optimal control problem}

The first step in the creation of the dataset, was to
solve an optimal control problem. And the first step
to do so is to formulate the optimal control problem

\subsubsection{Optimal control problem formulation}

In the optimal control problem $u$ is the input (in this case one dimensional)
to the system, while x is the state variable, and it's dimensionality
depends on the system tested

$$
\begin{aligned}
    x &= \begin{cases} 
        \begin{bmatrix} p \end{bmatrix} & \text{for ``simple'' system} \\
        \\
        \begin{bmatrix} p \\ v \end{bmatrix} & \text{for ``inertia'' system} 
    \end{cases} \\
    &\text{where:} \\
    &\quad p \text{ is the position} \\
    &\quad v \text{ is the velocity}
\end{aligned}
$$

Then the optimal control problem can be defined in simple therms with the equation underneath.

Notable components are $l$ (the cost function), that depends on the squared input as well as 
a positional cost, as well as $f$ which represent the dynamics of the system (and is 
therefore dependent on the selected system)
$$
\begin{aligned}
\mathop{\text{minimize}}_{X, U} \quad & \sum_{i=0}^{N-1} l(x_i, u_i) \\
\text{subject to} \quad & x_{i+1} = f(x_i, u_i) \quad i = 0 \dots N-1 \\
& x_0 = x_{init} \\
\text{where} \quad& \\
 & l(x,u) = \frac{1}{2} * u^2 + (p - 1.9) (p - 1.0) (p - 0.6) (p + 0.5) (p + 1.2) (p + 2.1) \\
 & f(x) = \begin{cases} 
    \begin{bmatrix} p \end{bmatrix}
    +  
    \begin{bmatrix}
    p + \delta t \cdot u
    \end{bmatrix}
    & \text{for ``simple'' system} \\

    \\

    \begin{bmatrix}
    p \\
    v
    \end{bmatrix}
    +  
    \begin{bmatrix}
    p + \delta t \cdot v + \frac{1}{2} \Delta t^2 \cdot u\\
    v + \Delta t \cdot u
    \end{bmatrix}
    & \text{for ``inertia'' system}

   \end{cases}
\end{aligned}
$$




\subsubsection{Optimization issues}
\label{sec:optimiaztion_issues}

During the optimization a few issues emerged, and the solutions are reported below.

The first issue was that the solver was biased towards the cost minimum that is found near $0$.
As we can see in figure \ref{fig:suboptimal_sol} from the initial position ($-1.3$)
the solver should converge in $-1.8$ as it is both closer, and lower cost.
However the solver prefer to ``walk uphill'' the cost's gradient and end up in a worst spot.

This is because no initial guess was provided, and the state variables where therefore
initialized at zero, making the solver biased

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{./images/suboptimal_solution.png}
\caption{An example on how the solver prefer a suboptimal solution found near $0$ to a better one found near $-1.8$}
\label{fig:suboptimal_sol}
\end{figure}

To solve this issue the state variable where initialized with random values within specific range,
this made it more more likely that the solver selected a different minimum than the one
in zero. However there was still an high variability on where the solver would end up (even with
the initial state being exactly the same), so to create a more accurate dataset
each input point was solved 10 times, and only the best solution was added to the dataset.


\subsection{Dataset creation}

The dataset creation was straightforward.
The input where generated by picking uniform samples within the following ranges:
\begin{itemize}
    \item {-2.15 to 1.95} for the position
    \item {-5 to 5} for the position velocity
\end{itemize}

The dataset size was selected to be 10k (meaning that 100k OCP problem where solved).
The calculation required approximately 45 minutes (for each one of the two systems tested)
on a 6 cores ryzen 5 5600 CPU. The implementation was multithreaded.


\section{Training the critic}

The training of the critic was done using the following parameters:
\begin{itemize}
    \item \textbf{Loss:} L1 loss (L2 and hubble where also tested, but found to be worst)
    \item \textbf{Optimizer:} AdamW with a learning rate of $10^{-4}$
    \item \textbf{LR Scheduler:} The learning rate was scheduled
        so that it was cut in half every time there where 10 iterations without any improvement.
    \item \textbf{Train-Test split} The training set was split 90/10 for training and validation
    \item \textbf{Batch size} 64 (other options where tested, but the difference seem small to none)
    \item \textbf{Iterations} Max iterations where set to 2000 (even tho the the algorithm was
often terminated after about 500 iterations for lack of improvements).


\end{itemize}
The final validation losses works out to be around 1.0 and 3.3 for the ``simple'' and ``inertia'' systems respectively,
while the training time was approximately 1 minute 45 seconds on an RTX 3060 ti GUP

The sizes of the networks where chosen by gradually increasing the size of the various layers
until the improvement was marginal. A similar logic was applied to the number of layers.
A ``shrinking'' architecture (where the layers start wide and sering once they get closer to the output)
was selected, as it is common doing in regression problems.

\subsection{Simple Critic}

The network for the ``simple'' system's critic ended up being a 4 layers FFNN with the respective
layer widths being (1,1024,256,1). All the activation layers are leaky ReLU.

In the figure \ref{fig:simple_critic_fn} we can see how accurate the critic is compared to the ground truth
\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{./images/simple_system___critic_function.png}
\caption{Simple Critic accuracy compared to ground truth}
\label{fig:simple_critic_fn}
\end{figure}


\subsection{Inertia Critic}

The network for the ``inertia'' system's critic ended up being a 5 layers FFNN with the respective
layer widths being (2,1024,512,256,1). All the activation layers are leaky ReLU.

In the figure \ref{fig:inertia_critic_fn} we can see how accurate the critic is compared to the ground truth
\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{./images/inertia_system___critic_function.png}
\caption{Inertia Critic accuracy compared to ground truth}
\label{fig:inertia_critic_fn}
\end{figure}


\section{Training the actor}

The actor's training was done by applying the following loss

$$
Loss = l(x,\pi(x)) + V(x,f(x,\pi(x)))
$$

Where $l$ is the cost function, $V$ is the value approximation (i.e. the critic) and $\pi$
is the policy trained (i.e. the actor).
When training using this loss the weights of the critic are kept frozen, while only the
weights of the actor are optimized.

The parameters used during training are the following:

\begin{itemize}
    \item \textbf{Optimizer:} AdamW with a learning rate of $5\cdot10^{-5}$
    \item \textbf{Batch size:} 2048 (other batch sizes where tested, but the difference was minimal)
    \item \textbf{Iterations} 5000 (where each iteration had only one batch with the input state being randomly generated)
\end{itemize}

Initially the training process did not work at all, and the reason turns out to be interesting:
During training the state ended up outside the range that was considered ``valid'' for the critic,
and therefore the output was inconsistent.
To solve this issue the the critic was edited so that the input is clipped if outside the validity range.

The training took approximately 11 seconds on an RTX 3060 ti GPU. The final losses are not reported
here as they are hard to interpret (given that they depends on the value function).
The size and shape of the network was selected in the same way that the critic's one was selected


\subsection{Simple Actor}


The network for the ``simple'' system's actor ended up being a 4 layers FFNN with the respective
layer widths being (1,512,128,1). All the activation layers are leaky ReLU.

In the figure \ref{fig:simple_actor_fn} we can see how accurate the actor is compared to the ground truth

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{./images/simple_system___actor_function.png}
\caption{Simple Actor accuracy compared to ground truth}
\label{fig:simple_actor_fn}
\end{figure}

One interesting detail to note in the chart is how the system struggles a bit in the
``discontinuity'' found around $0.7$.
The discontinuity is due to the fact that around that value the optimal
strategy changes from moving towards the minimum around $-1.8$ to moving to the minimum
around $1.8$.

This is potentially solvable using larger networks, but that would undermine the main
advantage of this approach which is speed.

\subsection{Inertia Actor}


The network for the ``inertia'' system's actor ended up being a 5 layers FFNN with the respective
layer widths being (1,1024,256,64,1). All the activation layers are leaky ReLU.


In the figure \ref{fig:inertia_actor_fn} we can see how accurate the actor is compared to the ground truth

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{./images/inertia_system___actor_function.png}
\caption{Inertia Actor accuracy compared to ground truth}
\label{fig:inertia_actor_fn}
\end{figure}

\section{Optimal control vs Actor Approximation}

In this section we report some trajectory that have being obtained with optimal control and with 
the actor to show how well the network was able to learn the optimal policy.

\subsection{Simple system trajectories}


We can note how the trajectories look pretty good.
In the first sub-figure of figure \ref{fig:simple_system_trajecotries} we can note how 
there is a small divergence from the steady state reached by the two control methods.


This can be explained by locking at figure \ref{fig:imperfect_min_point} that shows 
how the policy's value function has a local minimum that is slightly shifted
with respect to the real value function. And issue is reflected in the policy learned.

Initially this issue was much larger, and was solved by simply increasing the size of the policy network.
This trick stopped working at a certain point because the limitation started to become the
dataset's size.
\begin{figure}[H]
\centering
\begin{tabular}{cc}
  \includegraphics[width=70mm]{images/simple_system___actor_vs_ground_trough___0.png} &   \includegraphics[width=70mm]{images/simple_system___actor_vs_ground_trough___1.png} \\
  \includegraphics[width=70mm]{images/simple_system___actor_vs_ground_trough___2.png} &   \includegraphics[width=70mm]{images/simple_system___actor_vs_ground_trough___3.png} \\
\multicolumn{2}{c}{\includegraphics[width=70mm]{images/simple_system___actor_vs_ground_trough___4.png} }\\
\end{tabular}
\caption{Trajectory in the ``simple'' system}
\label{fig:simple_system_trajecotries}
\end{figure}



\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{./images/issue_with_imperfect_min_point.png}
\caption{Value function around $-1.8$}
\label{fig:imperfect_min_point}
\end{figure}


\subsection{Inertia system trajectories}

The inertia system trajectories also look good, and are in general really consistent
with the one calculated using optimal control.

The first subplot of figure \ref{fig:inertia_system_trajectories} is the worst result,
and this makes intuitive sense as it is one of the most complex one (where the initial 
position is close to the minimum cost, but the robot has an high velocity in the opposite
direction).

It is also worth noting that the closer the robot get to the end, the more
the behavior of the optimal control solver diverges from the one of the actor.
This is because the actor take one action at a time, and is considering
a full-length horizon for each action.
Meanwhile the optimal control solve the problem once, and the closer it get to the
horizon end the shorter the considered horizon become.

This effect can be noted in the first subplot of figure \ref{fig:inertia_system_trajectories}
where near the end the optimal control trajectory is still moving towards the bottom.
This is because the time horizon is about to end, and the cost of adjusting the trajectory
is grater tan the cost associated with drifting downward.

Meanwhile for the actor that is behaving as if it just started, and it had still a full
horizon ahead the adjustment cost is worth paying, resulting in a straighter trajectory.

\begin{figure}[H]
\centering
\begin{tabular}{cc}
  \includegraphics[width=80mm]{images/inertia_system___actor_vs_ground_trough___0.png} &   \includegraphics[width=70mm]{images/inertia_system___actor_vs_ground_trough___1.png} \\
  \includegraphics[width=70mm]{images/inertia_system___actor_vs_ground_trough___2.png} &   \includegraphics[width=70mm]{images/inertia_system___actor_vs_ground_trough___3.png} \\
  \includegraphics[width=70mm]{images/inertia_system___actor_vs_ground_trough___4.png} &   \includegraphics[width=70mm]{images/inertia_system___actor_vs_ground_trough___5.png} \\
\multicolumn{2}{c}{\includegraphics[width=70mm]{images/inertia_system___actor_vs_ground_trough___6.png} }\\
\end{tabular}
\caption{Trajectory in the ``inertia'' system}
\label{fig:inertia_system_trajectories}
\end{figure}





\section{Solving time of different methods}

The last step for this report is comparing four different solving
method to see the execution times and the trajectories accuracy compared.
The considered systems are the following:

\begin{itemize}
    \item \textbf{Optimal Control (best of one):} This method solve one optimal control problem and take the output.
        It suffers from the fact that it some-times find solutions that are locally optimal (for the
        reasons described in section \ref{sec:optimiaztion_issues})
    \item \textbf{Optimal Control (best of ten):} This method solve 10 optimal control problems
        and pick the best solution. It is slower but it does not suffers from the same issue 
        as the previous option (or at least the likelihood of that issue occurring is much lower)
    \item \textbf{Actor:} This is the simple implementation of the actor to calculate the trajectory
    \item \textbf{Optimal Control + actor initialization:} This method uses teh actor to calculate
        an initial guess, and then solve one optimal control problem with initialized variables.
        This solution also doesn't suffer from the issue plaguing the first one.
\end{itemize}

\subsection{results}

The trajectories with execution times can be seen in figure \ref{fig:simple_system_exec_time} and \ref{fig:inertia_system_exec_time}.
In the table below you can instead see a brief summary of how the various methods.
In general we can say that the last two methods are the ``pareto optimal'' one.

The use of an initial guess in the optimal control did provide a tiny speed improvement to the solver,
but this was canceled out by the time needed to run the actor, and the result is that the execution
time is on par with a normal solver (or perhaps is even slightly worse, but it's within the margin of error.)

\begin{table}[ht]
\centering
\resizebox{\textwidth}{!}{
    \begin{tabular}{|
    >{\columncolor[HTML]{FFFFFF}}l |c|
    >{\columncolor[HTML]{9AFF99}}c |
    >{\columncolor[HTML]{9AFF99}}c |}
    \hline
    \multicolumn{1}{|c|}{\cellcolor[HTML]{ECF4FF}\textbf{Strategy}} & \cellcolor[HTML]{ECF4FF}\textbf{Avg. exec. Time} & \cellcolor[HTML]{ECF4FF}\textbf{Trajectory type} & \cellcolor[HTML]{ECF4FF}\textbf{Local minimum issue} \\ \hline
    Optimal Control (best of one)                                   & \cellcolor[HTML]{FFFFC7} 0.18 [s]                       & Optimal                                          & \cellcolor[HTML]{FFCCC9}Yes                          \\ \hline
    Optimal Control (best of ten)                                   & \cellcolor[HTML]{FFCCC9} 1.73 [s]                   & Optimal                                          & No                                                   \\ \hline
    Actor                                                           & \cellcolor[HTML]{9AFF99} 0.03 [s]                   & \cellcolor[HTML]{FFCCC9}Approximated             & No                                                   \\ \hline
    Optimal Control + actor initialization                          & \cellcolor[HTML]{FFFFC7} 0.18 [s]                   & Optimal                                          & No                                                   \\ \hline
    \end{tabular}
}
\caption{Comparison between the tested solvers}
\end{table}
\subsubsection{Simple system plots}
\begin{figure}[H]
\centering
\begin{tabular}{cc}
  \includegraphics[width=70mm]{images/simple_system___execution_time_test___0.png} &   \includegraphics[width=70mm]{images/simple_system___execution_time_test___1.png} \\
  \includegraphics[width=70mm]{images/simple_system___execution_time_test___2.png} &   \includegraphics[width=70mm]{images/simple_system___execution_time_test___3.png} \\
\multicolumn{2}{c}{\includegraphics[width=70mm]{images/simple_system___execution_time_test___4.png} }\\
\end{tabular}
\caption{Different solution methods compared in the ``simple'' system}
\label{fig:simple_system_exec_time}
\end{figure}
\subsubsection{Inertia system plots}
\begin{figure}[H]
\centering
\begin{tabular}{cc}
  \includegraphics[width=70mm]{images/inertia_system___execution_time_test___0.png} &   \includegraphics[width=70mm]{images/inertia_system___execution_time_test___1.png} \\
  \includegraphics[width=70mm]{images/inertia_system___execution_time_test___2.png} &   \includegraphics[width=70mm]{images/inertia_system___execution_time_test___3.png} \\
  \includegraphics[width=70mm]{images/inertia_system___execution_time_test___4.png} &   \includegraphics[width=70mm]{images/inertia_system___execution_time_test___5.png} \\
\multicolumn{2}{c}{\includegraphics[width=70mm]{images/inertia_system___execution_time_test___6.png} }\\
\end{tabular}
\caption{Different solution methods compared in the ``inertia'' system}
\label{fig:inertia_system_exec_time}
\end{figure}






\end{document}