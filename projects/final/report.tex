\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{geometry}
\usepackage{float}
\usepackage[table,xcdraw]{xcolor}
\geometry{margin=1in}

\title{Optimization and Learning for Robot Control: Final Project}
\author{Luca Sartore - 256154}
\date{}


\begin{document}
\maketitle

\tableofcontents

\newpage

\section{Introduction}


This work aims to develop a neural network that approximates the output of an optimal control problem.

The selected system is straightforward: a robot moves in one dimension. At each iteration the robot
receives a cost that is proportional to the squared control input and to a positional cost.
The objective of the robot is to plan a trajectory with the lowest possible cost.

The tests were made with two systems. One is named ``Simple'', where the robot's velocity is proportional
to the control input, and the other is named ``Inertia'', where the robot has inertia and the
control input therefore becomes an acceleration.

The system is trained using a Critic-Actor paradigm, and the results are evaluated in two main ways:
\begin{itemize}
    \item \textbf{Trajectory:} Here the optimal trajectories are compared with the trajectories obtained by the neural network
    \item \textbf{Computation time} In this test we compare the computational cost of the various approaches used to solve the same problem
\end{itemize}


\section{Creating a dataset using Optimal Control}


\subsection{Solving the optimal control problem}

The first step in the creation of the dataset, was to
solve an optimal control problem. And the first step
to do so is to formulate the optimal control problem

\subsubsection{Optimal control problem formulation}

In the optimal control problem, $u$ is the input (in this case one-dimensional)
to the system, while $x$ is the state variable and its dimensionality
depends on the system tested.

$$
\begin{aligned}
    x &= \begin{cases} 
        \begin{bmatrix} p \end{bmatrix} & \text{for ``simple'' system} \\
        \\
        \begin{bmatrix} p \\ v \end{bmatrix} & \text{for ``inertia'' system} 
    \end{cases} \\
    &\text{where:} \\
    &\quad p \text{ is the position} \\
    &\quad v \text{ is the velocity}
\end{aligned}
$$

Then the optimal control problem can be defined in simple terms with the equation below.

Notable components are $l$ (the cost function), which depends on the squared input plus
a positional cost, and $f$, which represents the dynamics of the system (and is
therefore dependent on the selected system).
$$
\begin{aligned}
\mathop{\text{minimize}}_{X, U} \quad & \sum_{i=0}^{N-1} l(x_i, u_i) \\
\text{subject to} \quad & x_{i+1} = f(x_i, u_i) \quad i = 0 \dots N-1 \\
& x_0 = x_{init} \\
\text{where} \quad& \\
 & l(x,u) = \frac{1}{2} * u^2 + (p - 1.9) (p - 1.0) (p - 0.6) (p + 0.5) (p + 1.2) (p + 2.1) \\
 & f(x) = \begin{cases} 
    \begin{bmatrix} p \end{bmatrix}
    +  
    \begin{bmatrix}
    p + \delta t \cdot u
    \end{bmatrix}
    & \text{for ``simple'' system} \\

    \\

    \begin{bmatrix}
    p \\
    v
    \end{bmatrix}
    +  
    \begin{bmatrix}
    p + \delta t \cdot v + \frac{1}{2} \Delta t^2 \cdot u\\
    v + \Delta t \cdot u
    \end{bmatrix}
    & \text{for ``inertia'' system}

   \end{cases}
\end{aligned}
$$




\subsubsection{Optimization issues}
\label{sec:optimiaztion_issues}

During the optimization a few issues emerged, and the solutions are reported below.

The first issue was that the solver was biased towards the cost minimum that is found near $0$.
As we can see in figure \ref{fig:suboptimal_sol} from the initial position ($-1.3$)
the solver should converge in $-1.8$ as it is both closer, and lower cost.
However the solver prefer to ``walk uphill'' the cost's gradient and end up in a worst spot.

This is because no initial guess was provided, and the state variables were therefore
initialized at zero, making the solver biased.

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{./images/suboptimal_solution.png}
\caption{An example of how the solver prefers a suboptimal solution found near $0$ to a better one found near $-1.8$}
\label{fig:suboptimal_sol}
\end{figure}

To address this issue the state variables were initialized with random values within a specific range.
This made it more likely that the solver selected a different minimum than the one
at zero. However, there was still high variability in where the solver would end up (even with
the initial state being exactly the same). To create a more accurate dataset,
each input point was solved 10 times and only the best solution was added to the dataset.


\subsection{Dataset creation}

The dataset creation was straightforward.
The inputs were generated by picking uniform samples within the following ranges:
\begin{itemize}
    \item {-2.15 to 1.95} for the position
    \item {-5 to 5} for the position velocity
\end{itemize}

The dataset size was selected to be 10k (meaning that 100k OCP problems were solved).
The calculation required approximately 45 minutes (for each of the two systems tested)
on a 6-core Ryzen 5 5600 CPU. The implementation was multithreaded.


\section{Training the critic}

The training of the critic was done using the following parameters:
\begin{itemize}
    \item \textbf{Loss:} L1 loss (L2 and Huber were also tested, but found to be worse)
    \item \textbf{Optimizer:} AdamW with a learning rate of $10^{-4}$
    \item \textbf{LR Scheduler:} The learning rate was scheduled
        so that it was cut in half every time there were 10 iterations without any improvement.
    \item \textbf{Train-Test split:} The dataset was split 90/10 for training and validation
    \item \textbf{Batch size:} 64 (other options were tested, but the difference seemed minimal)
    \item \textbf{Iterations:} Max iterations were set to 2000 (even though the algorithm was
often terminated after about 500 iterations for lack of improvements).


\end{itemize}
The final validation losses work out to be around 1.0 and 3.3 for the ``simple'' and ``inertia'' systems respectively,
while the training time was approximately 1 minute 45 seconds on an RTX 3060 Ti GPU.

The sizes of the networks were chosen by gradually increasing the size of the various layers
until the improvement was marginal. A similar logic was applied to the number of layers.
A ``shrinking'' architecture (where the layers start wide and shrink as they get closer to the output)
was selected, as is common in regression problems.

\subsection{Simple Critic}

The network for the ``simple'' system's critic ended up being a 4-layer FFNN with the respective
layer widths (1,1024,256,1). All the activation functions are leaky ReLU.

In Figure \ref{fig:simple_critic_fn} we can see how accurate the critic is compared to the ground truth.
\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{./images/simple_system___critic_function.png}
\caption{Simple Critic accuracy compared to ground truth}
\label{fig:simple_critic_fn}
\end{figure}


\subsection{Inertia Critic}

The network for the ``inertia'' system's critic ended up being a 5-layer FFNN with the respective
layer widths (2,1024,512,256,1). All the activation functions are leaky ReLU.

In Figure \ref{fig:inertia_critic_fn} we can see how accurate the critic is compared to the ground truth.
\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{./images/inertia_system___critic_function.png}
\caption{Inertia Critic accuracy compared to ground truth}
\label{fig:inertia_critic_fn}
\end{figure}


\section{Training the actor}

The actor's training was done by applying the following loss

$$
Loss = l(x,\pi(x)) + V(x,f(x,\pi(x)))
$$

Where $l$ is the cost function, $V$ is the value approximation (i.e. the critic), and $\pi$
is the trained policy (i.e. the actor).
When training with this loss, the weights of the critic are kept frozen while only the
weights of the actor are optimized.

The parameters used during training are the following:

\begin{itemize}
    \item \textbf{Optimizer:} AdamW with a learning rate of $5\cdot10^{-5}$
    \item \textbf{Batch size:} 2048 (other batch sizes were tested, but the difference was minimal)
    \item \textbf{Iterations:} 5000 (where each iteration had only one batch with the input state being randomly generated)
\end{itemize}

Initially the training process did not work at all; the reason turned out to be interesting.
During training the state ended up outside the range considered "valid" for the critic,
and therefore the output was inconsistent. To solve this issue the critic was modified so that
the input is clipped if it falls outside the validity range.

The training took approximately 11 seconds on an RTX 3060 Ti GPU. The final losses are not reported
here as they are hard to interpret (given that they depend on the value function).
The size and shape of the network were selected in the same way the critic's were.


\subsection{Simple Actor}


The network for the ``simple'' system's actor ended up being a 4-layer FFNN with the respective
layer widths (1,512,128,1). All the activation functions are leaky ReLU.

In Figure \ref{fig:simple_actor_fn} we can see how accurate the actor is compared to the ground truth.

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{./images/simple_system___actor_function.png}
\caption{Simple Actor accuracy compared to ground truth}
\label{fig:simple_actor_fn}
\end{figure}

One interesting detail to note in the chart is how the system struggles a bit in the
``discontinuity'' found around $0.7$.
The discontinuity is due to the fact that around that value the optimal
strategy changes from moving towards the minimum around $-1.8$ to moving to the minimum
around $1.8$.

This is potentially solvable using larger networks, but that would undermine the main
advantage of this approach, which is speed, and would also potentially require a larger dataset.

\subsection{Inertia Actor}


The network for the ``inertia'' system's actor ended up being a 5-layer FFNN with the respective
layer widths (1,1024,256,64,1). All the activation functions are leaky ReLU.


In Figure \ref{fig:inertia_actor_fn} we can see how accurate the actor is compared to the ground truth.

\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{./images/inertia_system___actor_function.png}
\caption{Inertia Actor accuracy compared to ground truth}
\label{fig:inertia_actor_fn}
\end{figure}

\section{Optimal control vs Actor Approximation}

In this section we report some trajectories that have been obtained with optimal control and with
the actor to show how well the network was able to learn the optimal policy.

\subsection{Simple system trajectories}


We can note that the trajectories look generally good.
In the first sub-figure of Figure \ref{fig:simple_system_trajecotries} there is a small divergence from the steady state reached by the two control methods.


This can be explained by looking at Figure \ref{fig:imperfect_min_point}, which shows
how the critic's value function has a local minimum that is slightly shifted
with respect to the true value function. An issue is reflected in the learned policy.

Initially this issue was much larger and was reduced by increasing the size of the critic network.
This stopped helping once the dataset size became the limiting factor.
\begin{figure}[H]
\centering
\begin{tabular}{cc}
  \includegraphics[width=70mm]{images/simple_system___actor_vs_ground_trough___0.png} &   \includegraphics[width=70mm]{images/simple_system___actor_vs_ground_trough___1.png} \\
  \includegraphics[width=70mm]{images/simple_system___actor_vs_ground_trough___2.png} &   \includegraphics[width=70mm]{images/simple_system___actor_vs_ground_trough___3.png} \\
\multicolumn{2}{c}{\includegraphics[width=70mm]{images/simple_system___actor_vs_ground_trough___4.png} }\\
\end{tabular}
\caption{Trajectory in the ``simple'' system}
\label{fig:simple_system_trajecotries}
\end{figure}



\begin{figure}[H]
\centering
\includegraphics[width=0.6\textwidth]{./images/issue_with_imperfect_min_point.png}
\caption{Value function around $-1.8$}
\label{fig:imperfect_min_point}
\end{figure}


\subsection{Inertia system trajectories}

The inertia system trajectories also look good and are in general consistent
with those calculated using optimal control.

The first subplot of Figure \ref{fig:inertia_system_trajectories} is the worst result,
which makes intuitive sense as it is one of the most complex cases (where the initial
position is close to the minimum cost but the robot has a high velocity in the opposite
direction).

It is also worth noting that the closer the robot gets to the end, the more
the behavior of the optimal control solver diverges from that of the actor.
This is because the actor takes one action at a time and is trained to consider
a full-length horizon for each action.
Meanwhile, the optimal control solver solves the problem once, and the closer it gets to the
horizon end the shorter the considered horizon becomes.

This effect can be noted in the first subplot of Figure \ref{fig:inertia_system_trajectories},
where near the end the optimal control trajectory is still moving downward.
This is because the time horizon is about to end, and the cost of adjusting the trajectory
is greater than the cost associated with drifting downward.

Meanwhile, the actor behaves as if it just started and still has a full
horizon ahead; the adjustment cost is worth paying, resulting in a straighter trajectory.

\begin{figure}[H]
\centering
\begin{tabular}{cc}
  \includegraphics[width=70mm]{images/inertia_system___actor_vs_ground_trough___0.png} &   \includegraphics[width=70mm]{images/inertia_system___actor_vs_ground_trough___1.png} \\
  \includegraphics[width=70mm]{images/inertia_system___actor_vs_ground_trough___2.png} &   \includegraphics[width=70mm]{images/inertia_system___actor_vs_ground_trough___3.png} \\
  \includegraphics[width=70mm]{images/inertia_system___actor_vs_ground_trough___4.png} &   \includegraphics[width=70mm]{images/inertia_system___actor_vs_ground_trough___5.png} \\
\multicolumn{2}{c}{\includegraphics[width=70mm]{images/inertia_system___actor_vs_ground_trough___6.png} }\\
\end{tabular}
\caption{Trajectory in the ``inertia'' system}
\label{fig:inertia_system_trajectories}
\end{figure}





\section{Solving time of different methods}

The last step for this report is comparing four different solving
methods to see execution times and trajectory accuracy.
The considered systems are the following:

\begin{itemize}
    \item \textbf{Optimal Control (best of one):} This method solves one optimal control problem and takes the output.
        It suffers from the fact that it sometimes finds solutions that are locally (but not globally) optimal
        (for the reasons described in section \ref{sec:optimiaztion_issues}).
    \item \textbf{Optimal Control (best of ten):} This method solves 10 optimal control problems
        and picks the best solution. It is slower but does not suffer from the same issue
        as the previous option (or at least the likelihood of that issue occurring is much lower).
    \item \textbf{Actor:} This strategy simply involves using the actor to calculate the trajectory.
    \item \textbf{Optimal Control + actor initialization:} This method uses the actor to calculate
        an initial guess, and then solves one optimal control problem with initialized variables.
        This solution also doesn't suffer from the issue plaguing the first option.
\end{itemize}

\subsection{results}

The trajectories with execution times can be seen in figure \ref{fig:simple_system_exec_time} and \ref{fig:inertia_system_exec_time}.
In the table below you can instead see a brief summary of how the various methods performed.
In general we can say that the last two methods are the ``pareto optimal'' one.

The use of an initial guess in the optimal control did provide a tiny speed improvement to the solver,
but this was canceled out by the time needed to run the actor, and the result is that the execution
time is on par with a normal solver (or perhaps is even slightly worse, but it's within the margin of error.)

\begin{table}[ht]
\centering
\resizebox{\textwidth}{!}{
    \begin{tabular}{|
    >{\columncolor[HTML]{FFFFFF}}l |c|
    >{\columncolor[HTML]{9AFF99}}c |
    >{\columncolor[HTML]{9AFF99}}c |}
    \hline
    \multicolumn{1}{|c|}{\cellcolor[HTML]{ECF4FF}\textbf{Strategy}} & \cellcolor[HTML]{ECF4FF}\textbf{Avg. exec. Time} & \cellcolor[HTML]{ECF4FF}\textbf{Trajectory type} & \cellcolor[HTML]{ECF4FF}\textbf{Local minimum issue} \\ \hline
    Optimal Control (best of one)                                   & \cellcolor[HTML]{FFFFC7} 0.18 [s]                       & Optimal                                          & \cellcolor[HTML]{FFCCC9}Yes                          \\ \hline
    Optimal Control (best of ten)                                   & \cellcolor[HTML]{FFCCC9} 1.73 [s]                   & Optimal                                          & No                                                   \\ \hline
    Actor                                                           & \cellcolor[HTML]{9AFF99} 0.03 [s]                   & \cellcolor[HTML]{FFCCC9}Approximated             & No                                                   \\ \hline
    Optimal Control + actor initialization                          & \cellcolor[HTML]{FFFFC7} 0.18 [s]                   & Optimal                                          & No                                                   \\ \hline
    \end{tabular}
}
\caption{Comparison between the tested solvers}
\end{table}
\subsubsection{Simple system plots}
\begin{figure}[H]
\centering
\begin{tabular}{cc}
  \includegraphics[width=70mm]{images/simple_system___execution_time_test___0.png} &   \includegraphics[width=70mm]{images/simple_system___execution_time_test___1.png} \\
  \includegraphics[width=70mm]{images/simple_system___execution_time_test___2.png} &   \includegraphics[width=70mm]{images/simple_system___execution_time_test___3.png} \\
\multicolumn{2}{c}{\includegraphics[width=70mm]{images/simple_system___execution_time_test___4.png} }\\
\end{tabular}
\caption{Different solution methods compared in the ``simple'' system}
\label{fig:simple_system_exec_time}
\end{figure}
\subsubsection{Inertia system plots}
\begin{figure}[H]
\centering
\begin{tabular}{cc}
  \includegraphics[width=70mm]{images/inertia_system___execution_time_test___0.png} &   \includegraphics[width=70mm]{images/inertia_system___execution_time_test___1.png} \\
  \includegraphics[width=70mm]{images/inertia_system___execution_time_test___2.png} &   \includegraphics[width=70mm]{images/inertia_system___execution_time_test___3.png} \\
  \includegraphics[width=70mm]{images/inertia_system___execution_time_test___4.png} &   \includegraphics[width=70mm]{images/inertia_system___execution_time_test___5.png} \\
\multicolumn{2}{c}{\includegraphics[width=70mm]{images/inertia_system___execution_time_test___6.png} }\\
\end{tabular}
\caption{Different solution methods compared in the ``inertia'' system}
\label{fig:inertia_system_exec_time}
\end{figure}






\end{document}